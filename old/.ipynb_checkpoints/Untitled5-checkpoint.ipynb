{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.utils import (\n",
    "    saved_model_export_utils)\n",
    "from tensorflow.contrib.training.python.training import hparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMNS = ['age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
    "               'marital_status', 'occupation', 'relationship', 'race', 'gender',\n",
    "               'capital_gain', 'capital_loss', 'hours_per_week',\n",
    "               'native_country', 'income_bracket']\n",
    "CSV_COLUMN_DEFAULTS = [[0], [''], [0], [''], [0], [''], [''], [''], [''], [''],\n",
    "                       [0], [0], [0], [''], ['']]\n",
    "LABEL_COLUMN = 'income_bracket'\n",
    "LABELS = [' <=50K', ' >50K']\n",
    "\n",
    "# Define the initial ingestion of each feature used by your model.\n",
    "# Additionally, provide metadata about the feature.\n",
    "INPUT_COLUMNS = [\n",
    "    # Categorical base columns\n",
    "\n",
    "    # For categorical columns with known values we can provide lists\n",
    "    # of values ahead of time.\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        'gender', [' Female', ' Male']),\n",
    "\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        'race',\n",
    "        [' Amer-Indian-Eskimo', ' Asian-Pac-Islander',\n",
    "         ' Black', ' Other', ' White']\n",
    "    ),\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        'education',\n",
    "        [' Bachelors', ' HS-grad', ' 11th', ' Masters', ' 9th',\n",
    "         ' Some-college', ' Assoc-acdm', ' Assoc-voc', ' 7th-8th',\n",
    "         ' Doctorate', ' Prof-school', ' 5th-6th', ' 10th',\n",
    "         ' 1st-4th', ' Preschool', ' 12th']),\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        'marital_status',\n",
    "        [' Married-civ-spouse', ' Divorced', ' Married-spouse-absent',\n",
    "         ' Never-married', ' Separated', ' Married-AF-spouse', ' Widowed']),\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        'relationship',\n",
    "        [' Husband', ' Not-in-family', ' Wife', ' Own-child', ' Unmarried',\n",
    "         ' Other-relative']),\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        'workclass',\n",
    "        [' Self-emp-not-inc', ' Private', ' State-gov',\n",
    "         ' Federal-gov', ' Local-gov', ' ?', ' Self-emp-inc',\n",
    "         ' Without-pay', ' Never-worked']\n",
    "    ),\n",
    "\n",
    "    # For columns with a large number of values, or unknown values\n",
    "    # We can use a hash function to convert to categories.\n",
    "    tf.feature_column.categorical_column_with_hash_bucket(\n",
    "        'occupation', hash_bucket_size=100, dtype=tf.string),\n",
    "    tf.feature_column.categorical_column_with_hash_bucket(\n",
    "        'native_country', hash_bucket_size=100, dtype=tf.string),\n",
    "\n",
    "    # Continuous base columns.\n",
    "    tf.feature_column.numeric_column('age'),\n",
    "    tf.feature_column.numeric_column('education_num'),\n",
    "    tf.feature_column.numeric_column('capital_gain'),\n",
    "    tf.feature_column.numeric_column('capital_loss'),\n",
    "    tf.feature_column.numeric_column('hours_per_week'),\n",
    "]\n",
    "\n",
    "UNUSED_COLUMNS = set(CSV_COLUMNS) - {col.name for col in INPUT_COLUMNS} - \\\n",
    "    {LABEL_COLUMN}\n",
    "\n",
    "\n",
    "def build_estimator(config, embedding_size=8, hidden_units=None):\n",
    "  \"\"\"Build a wide and deep model for predicting income category.\n",
    "\n",
    "  Wide and deep models use deep neural nets to learn high level abstractions\n",
    "  about complex features or interactions between such features.\n",
    "  These models then combined the outputs from the DNN with a linear regression\n",
    "  performed on simpler features. This provides a balance between power and\n",
    "  speed that is effective on many structured data problems.\n",
    "\n",
    "  You can read more about wide and deep models here:\n",
    "  https://research.googleblog.com/2016/06/wide-deep-learning-better-together-with.html\n",
    "\n",
    "  To define model we can use the prebuilt DNNCombinedLinearClassifier class,\n",
    "  and need only define the data transformations particular to our dataset, and\n",
    "  then\n",
    "  assign these (potentially) transformed features to either the DNN, or linear\n",
    "  regression portion of the model.\n",
    "\n",
    "  Args:\n",
    "    config: tf.contrib.learn.RunConfig defining the runtime environment for the\n",
    "      estimator (including model_dir).\n",
    "    embedding_size: int, the number of dimensions used to represent categorical\n",
    "      features when providing them as inputs to the DNN.\n",
    "    hidden_units: [int], the layer sizes of the DNN (input layer first)\n",
    "    learning_rate: float, the learning rate for the optimizer.\n",
    "  Returns:\n",
    "    A DNNCombinedLinearClassifier\n",
    "  \"\"\"\n",
    "  (gender, race, education, marital_status, relationship,\n",
    "   workclass, occupation, native_country, age,\n",
    "   education_num, capital_gain, capital_loss, hours_per_week) = INPUT_COLUMNS\n",
    "  # Build an estimator.\n",
    "\n",
    "  # Reused Transformations.\n",
    "  # Continuous columns can be converted to categorical via bucketization\n",
    "  age_buckets = tf.feature_column.bucketized_column(\n",
    "      age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n",
    "\n",
    "  # Wide columns and deep columns.\n",
    "  wide_columns = [\n",
    "      # Interactions between different categorical features can also\n",
    "      # be added as new virtual features.\n",
    "      tf.feature_column.crossed_column(\n",
    "          ['education', 'occupation'], hash_bucket_size=int(1e4)),\n",
    "      tf.feature_column.crossed_column(\n",
    "          [age_buckets, race, 'occupation'], hash_bucket_size=int(1e6)),\n",
    "      tf.feature_column.crossed_column(\n",
    "          ['native_country', 'occupation'], hash_bucket_size=int(1e4)),\n",
    "      gender,\n",
    "      native_country,\n",
    "      education,\n",
    "      occupation,\n",
    "      workclass,\n",
    "      marital_status,\n",
    "      relationship,\n",
    "      age_buckets,\n",
    "  ]\n",
    "\n",
    "  deep_columns = [\n",
    "      # Use indicator columns for low dimensional vocabularies\n",
    "      tf.feature_column.indicator_column(workclass),\n",
    "      tf.feature_column.indicator_column(education),\n",
    "      tf.feature_column.indicator_column(marital_status),\n",
    "      tf.feature_column.indicator_column(gender),\n",
    "      tf.feature_column.indicator_column(relationship),\n",
    "      tf.feature_column.indicator_column(race),\n",
    "\n",
    "      # Use embedding columns for high dimensional vocabularies\n",
    "      tf.feature_column.embedding_column(\n",
    "          native_country, dimension=embedding_size),\n",
    "      tf.feature_column.embedding_column(occupation, dimension=embedding_size),\n",
    "      age,\n",
    "      education_num,\n",
    "      capital_gain,\n",
    "      capital_loss,\n",
    "      hours_per_week,\n",
    "  ]\n",
    "\n",
    "  return tf.estimator.DNNLinearCombinedClassifier(\n",
    "      config=config,\n",
    "      linear_feature_columns=wide_columns,\n",
    "      dnn_feature_columns=deep_columns,\n",
    "      dnn_hidden_units=hidden_units or [100, 70, 50, 25]\n",
    "  )\n",
    "\n",
    "\n",
    "def parse_label_column(label_string_tensor):\n",
    "  \"\"\"Parses a string tensor into the label tensor\n",
    "  Args:\n",
    "    label_string_tensor: Tensor of dtype string. Result of parsing the\n",
    "    CSV column specified by LABEL_COLUMN\n",
    "  Returns:\n",
    "    A Tensor of the same shape as label_string_tensor, should return\n",
    "    an int64 Tensor representing the label index for classification tasks,\n",
    "    and a float32 Tensor representing the value for a regression task.\n",
    "  \"\"\"\n",
    "  # Build a Hash Table inside the graph\n",
    "  table = tf.contrib.lookup.index_table_from_tensor(tf.constant(LABELS))\n",
    "\n",
    "  # Use the hash table to convert string labels to ints and one-hot encode\n",
    "  return table.lookup(label_string_tensor)\n",
    "\n",
    "\n",
    "# ************************************************************************\n",
    "# YOU NEED NOT MODIFY ANYTHING BELOW HERE TO ADAPT THIS MODEL TO YOUR DATA\n",
    "# ************************************************************************\n",
    "\n",
    "\n",
    "def csv_serving_input_fn():\n",
    "  \"\"\"Build the serving inputs.\"\"\"\n",
    "  csv_row = tf.placeholder(\n",
    "      shape=[None],\n",
    "      dtype=tf.string\n",
    "  )\n",
    "  features = parse_csv(csv_row)\n",
    "  features.pop(LABEL_COLUMN)\n",
    "  return tf.estimator.export.ServingInputReceiver(features, {'csv_row': csv_row})\n",
    "\n",
    "\n",
    "def example_serving_input_fn():\n",
    "  \"\"\"Build the serving inputs.\"\"\"\n",
    "  example_bytestring = tf.placeholder(\n",
    "      shape=[None],\n",
    "      dtype=tf.string,\n",
    "  )\n",
    "  feature_scalars = tf.parse_example(\n",
    "      example_bytestring,\n",
    "      tf.feature_column.make_parse_example_spec(INPUT_COLUMNS)\n",
    "  )\n",
    "  return tf.estimator.export.ServingInputReceiver(\n",
    "      features,\n",
    "      {'example_proto': example_bytestring}\n",
    "  )\n",
    "\n",
    "# [START serving-function]\n",
    "def json_serving_input_fn():\n",
    "  \"\"\"Build the serving inputs.\"\"\"\n",
    "  inputs = {}\n",
    "  for feat in INPUT_COLUMNS:\n",
    "    inputs[feat.name] = tf.placeholder(shape=[None], dtype=feat.dtype)\n",
    "    \n",
    "  return tf.estimator.export.ServingInputReceiver(inputs, inputs)\n",
    "# [END serving-function]\n",
    "\n",
    "SERVING_FUNCTIONS = {\n",
    "    'JSON': json_serving_input_fn,\n",
    "    'EXAMPLE': example_serving_input_fn,\n",
    "    'CSV': csv_serving_input_fn\n",
    "}\n",
    "\n",
    "\n",
    "def parse_csv(rows_string_tensor):\n",
    "  \"\"\"Takes the string input tensor and returns a dict of rank-2 tensors.\"\"\"\n",
    "\n",
    "  # Takes a rank-1 tensor and converts it into rank-2 tensor\n",
    "  # Example if the data is ['csv,line,1', 'csv,line,2', ..] to\n",
    "  # [['csv,line,1'], ['csv,line,2']] which after parsing will result in a\n",
    "  # tuple of tensors: [['csv'], ['csv']], [['line'], ['line']], [[1], [2]]\n",
    "  row_columns = tf.expand_dims(rows_string_tensor, -1)\n",
    "  columns = tf.decode_csv(row_columns, record_defaults=CSV_COLUMN_DEFAULTS)\n",
    "  features = dict(zip(CSV_COLUMNS, columns))\n",
    "\n",
    "  # Remove unused columns\n",
    "  for col in UNUSED_COLUMNS:\n",
    "    features.pop(col)\n",
    "  return features\n",
    "\n",
    "\n",
    "def input_fn(filenames,\n",
    "                      num_epochs=None,\n",
    "                      shuffle=True,\n",
    "                      skip_header_lines=0,\n",
    "                      batch_size=200):\n",
    "  \"\"\"Generates features and labels for training or evaluation.\n",
    "  This uses the input pipeline based approach using file name queue\n",
    "  to read data so that entire data is not loaded in memory.\n",
    "\n",
    "  Args:\n",
    "      filenames: [str] list of CSV files to read data from.\n",
    "      num_epochs: int how many times through to read the data.\n",
    "        If None will loop through data indefinitely\n",
    "      shuffle: bool, whether or not to randomize the order of data.\n",
    "        Controls randomization of both file order and line order within\n",
    "        files.\n",
    "      skip_header_lines: int set to non-zero in order to skip header lines\n",
    "        in CSV files.\n",
    "      batch_size: int First dimension size of the Tensors returned by\n",
    "        input_fn\n",
    "  Returns:\n",
    "      A (features, indices) tuple where features is a dictionary of\n",
    "        Tensors, and indices is a single Tensor of label indices.\n",
    "  \"\"\"\n",
    "  filename_dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "  if shuffle:\n",
    "    # Process the files in a random order.\n",
    "    filename_dataset = filename_dataset.shuffle(len(filenames))\n",
    "    \n",
    "  # For each filename, parse it into one element per line, and skip the header\n",
    "  # if necessary.\n",
    "  dataset = filename_dataset.flat_map(\n",
    "      lambda filename: tf.data.TextLineDataset(filename).skip(skip_header_lines))\n",
    "  \n",
    "  dataset = dataset.map(parse_csv)\n",
    "  if shuffle:\n",
    "    dataset = dataset.shuffle(buffer_size=batch_size * 10)\n",
    "  dataset = dataset.repeat(num_epochs)\n",
    "  dataset = dataset.batch(batch_size)\n",
    "  iterator = dataset.make_one_shot_iterator()\n",
    "  features = iterator.get_next()\n",
    "  return features, parse_label_column(features.pop(LABEL_COLUMN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(hparams):\n",
    "  \"\"\"Run the training and evaluate using the high level API\"\"\"\n",
    "\n",
    "  train_input = lambda: input_fn(\n",
    "      hparams.train_files,\n",
    "      num_epochs=hparams.num_epochs,\n",
    "      batch_size=hparams.train_batch_size\n",
    "  )\n",
    "\n",
    "  # Don't shuffle evaluation data\n",
    "  eval_input = lambda: input_fn(\n",
    "      hparams.eval_files,\n",
    "      batch_size=hparams.eval_batch_size,\n",
    "      shuffle=False\n",
    "  )\n",
    "\n",
    "  train_spec = tf.estimator.TrainSpec(train_input,\n",
    "                                      max_steps=hparams.train_steps\n",
    "                                      )\n",
    "\n",
    "  exporter = tf.estimator.FinalExporter('census',\n",
    "          SERVING_FUNCTIONS[hparams.export_format])\n",
    "  eval_spec = tf.estimator.EvalSpec(eval_input,\n",
    "                                    steps=hparams.eval_steps,\n",
    "                                    exporters=[exporter],\n",
    "                                    name='census-eval'\n",
    "                                    )\n",
    "\n",
    "  run_config = tf.estimator.RunConfig()\n",
    "  run_config = run_config.replace(model_dir=hparams.job_dir)\n",
    "  print('model dir {}'.format(run_config.model_dir))\n",
    "  estimator = build_estimator(\n",
    "      embedding_size=hparams.embedding_size,\n",
    "      # Construct layers sizes with exponetial decay\n",
    "      hidden_units=[\n",
    "          max(2, int(hparams.first_layer_size *\n",
    "                     hparams.scale_factor**i))\n",
    "          for i in range(hparams.num_layers)\n",
    "      ],\n",
    "      config=run_config\n",
    "  )\n",
    "\n",
    "  tf.estimator.train_and_evaluate(estimator,\n",
    "                                  train_spec,\n",
    "                                  eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = tf.contrib.training.HParams(\n",
    "    job_dir='output',\n",
    "    train_files=['data/adult.data.csv'],\n",
    "    eval_files=['data/adult.test.csv'],\n",
    "    train_steps=100,\n",
    "    eval_steps=10,\n",
    "    export_format='JSON',\n",
    "    embedding_size=8,\n",
    "    num_layers=4,\n",
    "    first_layer_size=100,\n",
    "    scale_factor=0.7,\n",
    "    num_epochs=1,\n",
    "    train_batch_size=40,\n",
    "    eval_batch_size=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model dir output\n",
      "INFO:tensorflow:Using config: {'_is_chief': True, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_num_worker_replicas': 1, '_num_ps_replicas': 0, '_service': None, '_task_id': 0, '_log_step_count_steps': 100, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_model_dir': 'output', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3fec91ef60>, '_session_config': None, '_save_checkpoints_secs': 600, '_master': '', '_keep_checkpoint_every_n_hours': 10000, '_task_type': 'worker'}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-18-07:31:11\n",
      "INFO:tensorflow:Restoring parameters from output/model.ckpt-100\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-18-07:31:13\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.79, accuracy_baseline = 0.7475, auc = 0.79067194, auc_precision_recall = 0.63604504, average_loss = 0.47782144, global_step = 100, label/mean = 0.2525, loss = 19.112858, prediction/mean = 0.2590744\n",
      "INFO:tensorflow:Performing the final export in the end of training.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'classification' : Classification input must be a single string Tensor; got {'capital_gain': <tf.Tensor 'Placeholder_10:0' shape=(?,) dtype=float32>, 'marital_status': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=string>, 'education_num': <tf.Tensor 'Placeholder_9:0' shape=(?,) dtype=float32>, 'native_country': <tf.Tensor 'Placeholder_7:0' shape=(?,) dtype=string>, 'age': <tf.Tensor 'Placeholder_8:0' shape=(?,) dtype=float32>, 'education': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=string>, 'capital_loss': <tf.Tensor 'Placeholder_11:0' shape=(?,) dtype=float32>, 'relationship': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=string>, 'gender': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=string>, 'occupation': <tf.Tensor 'Placeholder_6:0' shape=(?,) dtype=string>, 'workclass': <tf.Tensor 'Placeholder_5:0' shape=(?,) dtype=string>, 'hours_per_week': <tf.Tensor 'Placeholder_12:0' shape=(?,) dtype=float32>, 'race': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=string>}\n",
      "INFO:tensorflow:'serving_default' : Classification input must be a single string Tensor; got {'capital_gain': <tf.Tensor 'Placeholder_10:0' shape=(?,) dtype=float32>, 'marital_status': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=string>, 'education_num': <tf.Tensor 'Placeholder_9:0' shape=(?,) dtype=float32>, 'native_country': <tf.Tensor 'Placeholder_7:0' shape=(?,) dtype=string>, 'age': <tf.Tensor 'Placeholder_8:0' shape=(?,) dtype=float32>, 'education': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=string>, 'capital_loss': <tf.Tensor 'Placeholder_11:0' shape=(?,) dtype=float32>, 'relationship': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=string>, 'gender': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=string>, 'occupation': <tf.Tensor 'Placeholder_6:0' shape=(?,) dtype=string>, 'workclass': <tf.Tensor 'Placeholder_5:0' shape=(?,) dtype=string>, 'hours_per_week': <tf.Tensor 'Placeholder_12:0' shape=(?,) dtype=float32>, 'race': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=string>}\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'capital_gain': <tf.Tensor 'Placeholder_10:0' shape=(?,) dtype=float32>, 'marital_status': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=string>, 'education_num': <tf.Tensor 'Placeholder_9:0' shape=(?,) dtype=float32>, 'native_country': <tf.Tensor 'Placeholder_7:0' shape=(?,) dtype=string>, 'age': <tf.Tensor 'Placeholder_8:0' shape=(?,) dtype=float32>, 'education': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=string>, 'capital_loss': <tf.Tensor 'Placeholder_11:0' shape=(?,) dtype=float32>, 'relationship': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=string>, 'gender': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=string>, 'occupation': <tf.Tensor 'Placeholder_6:0' shape=(?,) dtype=string>, 'workclass': <tf.Tensor 'Placeholder_5:0' shape=(?,) dtype=string>, 'hours_per_week': <tf.Tensor 'Placeholder_12:0' shape=(?,) dtype=float32>, 'race': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=string>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from output/model.ckpt-100\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"output/export/census/temp-b'1531899074'/saved_model.pb\"\n"
     ]
    }
   ],
   "source": [
    "run_experiment(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS_IDS  CLASSES  LOGISTIC               LOGITS                 PROBABILITIES\r\n",
      "[0]        [u'0']   [0.19064758718013763]  [-1.4458078145980835]  [0.809352457523346, 0.19064758718013763]\r\n"
     ]
    }
   ],
   "source": [
    "!gcloud ml-engine local predict --model-dir=output/export/census/1531882849 --json-instances=data/test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
